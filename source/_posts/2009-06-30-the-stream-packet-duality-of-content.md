---
layout: post
featured: false
title: "The Stream-Packet Duality of Content"
permalink: /2009/06/30/the-stream-packet-duality-of-content/
dsq_thread_id:
  - 23575422
categories:
  - commentary
  - web ideas
excerpt: "Incoming content at the speed of light."
show_excerpt: true
---
*This post develops the conceptual language surrounding the product ideas in my previous post, [Filtration as a Tonic for Internet Vertigo][1].*

Towards the beginning of his aforementioned [blog post][2], John Borthwick writes:

> what emerges out of this is a new metaphor — think streams vs. pages

I think that this progression of metaphors is moving in the right direction, but it needs to be taken further. Streams consist of web content that is delivered directly to the user (to a Twitter client, to an RSS reader, etc), and this is in direct contrast to content that lives on specific pages to which a user must navigate in a web browser. Streams are dynamic, up-to-date and are delivered in (near) real time, while pages are static and not necessarily current.

Streams, however, are just collections of individual pieces of content, or packets. Tweets, status updates, blog posts, photos, mp3 files, and video clips are all discrete packets of content. These packets are the units which a user actually consumes as information, and streams are just a way to group those packets over time, usually based on on source (such as a specific blog) or topic (such as a search term on Twitter). But there are potentially more potent ways in which these packets can be organized than by their original source/topic, and this is important because these streams tend to be overwhelming in their aggregate. Borthwick continues about the future of content delivery via streams:

> Overload isn't a problem anymore since we have no choice but to acknowledge that we cant wade through all this information. This isn't an inbox we have to empty, or a page we have to get to the bottom of — it's a flow of data that we can dip into at will but we cant attempt to gain an all encompassing view of it.

I suspect that there is a more optimistic solution, however, and that there are better-than-random ways to organize the flow of content from our collections of streams. There will be some packets in these streams that are more important to individual users than others, so I want services that surface the best ones and hide the others. I predict a future in which streams are cut, rearranged, reordered and remixed into a single source of content that always has that moment's most important/relevant/enjoyable packet at the front of the queue. The future of content on the web will be based on tools that focus on perfecting the delivery of these individual packets of information to users for consumption.

I agree with Borthwick, and think that the re-conceptualization of the destination web of pages into a real time stream of pages is the next (or current?) big thing. But I think the re-conceptualization of those streams as collections of individual operable packets is the big thing after that.

 [1]: /2009/06/22/filtration-as-a-tonic-for-internet-vertigo/
 [2]: http://www.borthwick.com/weblog/2009/05/13/699/
